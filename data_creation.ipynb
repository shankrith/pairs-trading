{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.stattools import adfuller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = r\"data\"\n",
    "STORE = DATA_PATH + '/assets.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_correlated_assets(df, cutoff = 0.99, verbose = False):\n",
    "    corr = df.corr().stack()\n",
    "    corr = corr[corr < 1]\n",
    "    corr_subset = corr[corr.abs() >= cutoff].index\n",
    "    keep, drop = set(), set()\n",
    "    for s1, s2 in corr_subset:\n",
    "        if s1 not in keep:\n",
    "            if s2 not in keep:\n",
    "                keep.add(s1)\n",
    "                drop.add(s2)\n",
    "            else:\n",
    "                drop.add(s1)\n",
    "        else:\n",
    "            keep.discard(s2)\n",
    "            drop.add(s2)\n",
    "    df = df.drop(drop, axis = 1)\n",
    "    if verbose:\n",
    "        return [df, (corr, drop)]\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_stationarity(df):\n",
    "    results = []\n",
    "    for ticker, prices in df.items():\n",
    "        results.append([ticker, adfuller(prices, regression='ct')[1]])\n",
    "    return pd.DataFrame(results, columns = ['ticker', 'adf']).sort_values('adf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stationary_assets(df, pval = 0.05, verbose = False):\n",
    "    test_result = check_stationarity(df)\n",
    "    stationary = test_result.loc[test_result.adf <= pval, 'ticker'].tolist()\n",
    "    if verbose:\n",
    "        return [df.drop(stationary, axis = 1), stationary]\n",
    "    return df.drop(stationary, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_assets(asset_class='stocks', n = 500, start = 2013, end = 2023):\n",
    "    idx = pd.IndexSlice\n",
    "    with pd.HDFStore(STORE) as store:\n",
    "        df = (pd.concat([store[f'stooq/us/nasdaq/{asset_class}/prices'],\n",
    "                        store[f'stooq/us/nyse/{asset_class}/prices']])\n",
    "             .loc[lambda df: ~df.index.duplicated()]\n",
    "             .sort_index()\n",
    "             .loc[idx[:, f'{start}':f'{end}'], :]\n",
    "             .assign(dv = lambda df: df.close.mul(df.volume)))\n",
    "\n",
    "    most_traded = (df.groupby(level = 'ticker')\n",
    "                   .dv.mean()\n",
    "                   .nlargest(n=n).index)\n",
    "\n",
    "    df = (df.loc[idx[most_traded, :], 'close']\n",
    "          .unstack('ticker')\n",
    "          .ffill(limit = 5)\n",
    "          .dropna(axis = 1))\n",
    "\n",
    "    df = remove_correlated_assets(df)\n",
    "    df = remove_stationary_assets(df)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for asset_class, n in [('etfs', 500), ('stocks', 250)]:\n",
    "    df = select_assets(asset_class = asset_class, n = n)\n",
    "    df.to_hdf(DATA_PATH + r'/etfs_stocks_universe.h5', f'{asset_class}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.DataFrame()\n",
    "for asset_class, n in [('etfs', 500), ('stocks', 250)]:\n",
    "    with pd.HDFStore(STORE) as store:\n",
    "        df = (pd.concat([store[f'stooq/us/nasdaq/{asset_class}/prices'],\n",
    "                        store[f'stooq/us/nyse/{asset_class}/prices']])\n",
    "                .loc[lambda df: ~df.index.duplicated()]\n",
    "                .sort_index())\n",
    "                # .loc[idx[:, f'{start}':f'{end}'], :]\n",
    "                # .assign(dv = lambda df: df.close.mul(df.volume)))\n",
    "    all_df = pd.concat([all_df, df])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Candidate Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = r\"data\"\n",
    "STORE = DATA_PATH + r\"\\backtest.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "critical_values = {0: {0.9: 13.4294, 0.95: 15.4943, 0.99: 19.9349},\n",
    "                   1: {0.9: 2.7055, 0.95: 3.8415, 0.99: 6.6349}}\n",
    "\n",
    "trace0_cv = critical_values[0][0.99]\n",
    "trace1_cv = critical_values[1][0.99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.HDFStore(STORE) as store:\n",
    "    cointegration_res = store['cointegration_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_candidate_pairs(df):\n",
    "    \n",
    "    df['joh_sig'] = ((df['trace0'] > trace0_cv) & (df['trace1'] > trace1_cv))\n",
    "    df['eg'] = df[['eg1','eg2']].min(axis = 1) \n",
    "    df['s1_dep'] = (df['eg1'] < df['eg2'])\n",
    "    df['eg_sig'] = df['eg'] < 0.05\n",
    "    df = df.drop(['eig0', 'eig1', 'w1', 'w2', 'eg1', 'eg2', 'trace0', 'trace1'], axis = 1) \n",
    "\n",
    "    candidates = df[df['joh_sig'] | df['eg_sig']]\n",
    "    candidates['y'] = candidates.apply(lambda x: x['s1'] if x['s1_dep'] else x['s2'], axis = 1)\n",
    "    candidates['x'] = candidates.apply(lambda x: x['s2'] if x['s1_dep'] else x['s1'], axis = 1)\n",
    "    candidates = candidates.drop(['s1', 's2', 'joh_sig', 's1_dep', 'eg_sig'], axis = 1)\n",
    "    \n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = select_candidate_pairs(cointegration_res)\n",
    "candidates.to_hdf(STORE, \"candidates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pricing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = pd.IndexSlice\n",
    "DATA_PATH = r\"C:\\Personal\\time-series\\data\"\n",
    "STORE = DATA_PATH + '/assets.h5'\n",
    "with pd.HDFStore(STORE) as store:\n",
    "    prices = (pd.concat([\n",
    "        store['stooq/us/nyse/stocks/prices'],\n",
    "        store['stooq/us/nyse/etfs/prices'],\n",
    "        store['stooq/us/nasdaq/etfs/prices'],\n",
    "        store['stooq/us/nasdaq/stocks/prices']])\n",
    "                .sort_index()\n",
    "                .loc[idx[:, '2013':'2023'], :])\n",
    "print(prices.info())\n",
    "prices.to_hdf('data/backtest.h5', 'prices')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Deletion from HDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tables\n",
    "# with tables.open_file(r'data/backtest.h5', mode = 'r+') as h5_file:\n",
    "    # h5_file.remove_node('/test1/trades', recursive = True)\n",
    "    # h5_file.remove_node('/test2/trades', recursive = True)\n",
    "    # h5_file.remove_node('/test3/trades', recursive = True)\n",
    "    # h5_file.remove_node('/prices_wide', recursive = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
